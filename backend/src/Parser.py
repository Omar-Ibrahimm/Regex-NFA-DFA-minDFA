"""
Parser Module for Regular Expression Processing

This module implements a recursive descent parser that converts a sequence of tokens
representing a regular expression into an abstract syntax tree (AST). The parser
follows standard regular expression grammar including support for:
- Alternation (|)
- Concatenation
- Repetition operators (*, +, ?)
- Character classes [a-z]
- Grouping with parentheses

The AST generated by this parser can then be used to create a finite state machine
or for other processing of regular expressions.
"""
from typing import Tuple
from Lexer import Token, TokenType
from AST import *

class Parser:
    """
    A recursive descent parser for regular expressions.
    
    This parser converts a stream of tokens into an Abstract Syntax Tree (AST)
    representation of the regular expression.
    """
    def __init__(self, tokens: Tuple[Token, ...]):
        """
        Initialize the parser with a sequence of tokens.
        
        Args:
            tokens: A tuple of Token objects to parse
        """
        self.tokens = tokens
        self.current = 0

    def parse(self) -> AstNode:
        """
        Parse the token stream into an AST.
        
        Returns:
            The root node of the AST
        """
        return self.parseExpression()
    
    def parseExpression(self) -> AstNode:
        """
        Parse an expression, which consists of one or more terms separated by OR operators.
        
        Grammar: expression -> term ('|' term)*
        
        Returns:
            An AST node representing the expression
        """
        ast = self.parseTerm()
        while self.match(TokenType.OR):
            right = self.parseTerm()
            ast = OrAstNode(ast, right)
        return ast
    
    def parseTerm(self) -> AstNode:
        """
        Parse a term, which consists of one or more factors in concatenation.
        
        Grammar: term -> factor (factor)*
        
        Returns:
            An AST node representing the term
        """
        ast = self.parseFactor()
        while self.current < len(self.tokens) and self.tokens[self.current].tokenType in [TokenType.CONCAT]:
            self.match(TokenType.CONCAT)
            right = self.parseFactor()
            ast = ConcatAstNode(ast, right)
        return ast
    
    def parseFactor(self) -> AstNode:
        """
        Parse a factor, which is a primary followed by zero or more unary operators.
        
        Grammar: factor -> primary ('*' | '+' | '?')*
        
        Returns:
            An AST node representing the factor
        """
        ast = self.parsePrimary()
        while self.current < len(self.tokens) and self.tokens[self.current].tokenType in [
            TokenType.STAR, TokenType.PLUS, TokenType.OPTIONAL
        ]:
            if self.match(TokenType.STAR):
                ast = StarAstNode(ast)
            elif self.match(TokenType.PLUS):
                ast = PlusAstNode(ast)
            elif self.match(TokenType.OPTIONAL):
                ast = OptionalAstNode(ast)
        return ast
    
    def parsePrimary(self) -> AstNode:
        """
        Parse a primary expression (literal, group, or character class).
        
        Grammar: primary -> LITERAL | '(' expression ')' | '[' character_class ']'
        
        Returns:
            An AST node representing the primary
            
        Raises:
            Exception: If an unexpected token is encountered
        """
        if self.match(TokenType.LITERAL):
            return LiteralAstNode(self.tokens[self.current - 1].value)
        elif self.match(TokenType.LPAREN):
            ast = self.parseExpression()
            self.match(TokenType.RPAREN)
            return ast
        elif self.match(TokenType.LBRACKET):
            char_set = self.parseCharacterClass()
            self.match(TokenType.RBRACKET)
            return CharacterClassAstNode(char_set)
        else:
            raise Exception("Unexpected token")
    
    def parseCharacterClass(self) -> set:
        """
        Parse a character class expression inside square brackets.
        
        Handles character ranges (a-z) and individual characters.
        
        Returns:
            A set of characters represented by the character class
        """
        char_set = set()
        buffer = []
        
        # Collect all tokens until the closing bracket
        while self.current < len(self.tokens) and self.tokens[self.current].tokenType != TokenType.RBRACKET:
            token = self.tokens[self.current]
            if token.tokenType == TokenType.LITERAL or token.tokenType == TokenType.HYPHEN:
                buffer.append(token)
                self.current += 1
            else:
                self.current += 1
        
        # Process the buffer to handle ranges and individual characters
        i = 0
        while i < len(buffer):
            # Check for character range pattern: literal-literal
            if (i+2 < len(buffer) and 
                buffer[i].tokenType == TokenType.LITERAL and 
                buffer[i+1].tokenType == TokenType.HYPHEN and 
                buffer[i+2].tokenType == TokenType.LITERAL):
                
                start_char = buffer[i].value
                end_char = buffer[i+2].value
                
                if self.isValidRange(start_char, end_char):
                    # Add all characters in the range
                    for c in range(ord(start_char), ord(end_char) + 1):
                        char_set.add(chr(c))
                    i += 3
                else:
                    # If not a valid range, treat as individual character
                    char_set.add(start_char)
                    i += 1
            else:
                # Handle individual character
                if buffer[i].tokenType == TokenType.LITERAL or buffer[i].tokenType == TokenType.HYPHEN:
                    char_set.add(buffer[i].value)
                i += 1
        
        return char_set

    def isValidRange(self, start: str, end: str) -> bool:
        """
        Check if a character range is valid.
        
        A valid range must:
        1. Have start character <= end character
        2. Both characters must be in the same category (lowercase, uppercase, or digits)
        
        Args:
            start: Starting character of the range
            end: Ending character of the range
            
        Returns:
            True if the range is valid, False otherwise
        """
        start_ord, end_ord = ord(start), ord(end)
        
        # End must be greater than or equal to start
        if start_ord > end_ord:
            return False
            
        # Check if both are in the same category
        if 'a' <= start <= 'z' and 'a' <= end <= 'z':
            return True
        if 'A' <= start <= 'Z' and 'A' <= end <= 'Z':
            return True
        if '0' <= start <= '9' and '0' <= end <= '9':
            return True
            
        return False
    
    def match(self, tokenType: TokenType) -> bool:
        """
        Check if the current token matches the expected type and advance if it does.
        
        Args:
            tokenType: The expected token type
            
        Returns:
            True if the current token matched and was consumed, False otherwise
        """
        if self.current < len(self.tokens) and self.tokens[self.current].tokenType == tokenType:
            self.current += 1
            return True
        return False
